{"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"name":"python","version":"3.7.12","mimetype":"text/x-python","codemirror_mode":{"name":"ipython","version":3},"pygments_lexer":"ipython3","nbconvert_exporter":"python","file_extension":".py"}},"nbformat_minor":4,"nbformat":4,"cells":[{"cell_type":"code","source":"#Load the librarys\nimport pandas as pd #To work with dataset\nimport numpy as np #Math library\nimport matplotlib.gridspec as gridspec\nimport seaborn as sns #Graph library that use matplot in background\nimport matplotlib.pyplot as plt #to plot some parameters in seaborn\nimport warnings\n# Preparation  \nfrom sklearn.preprocessing import LabelEncoder, OrdinalEncoder\nfrom sklearn.preprocessing import OneHotEncoder\nfrom sklearn.preprocessing import PowerTransformer, StandardScaler,Normalizer,RobustScaler,MaxAbsScaler,MinMaxScaler,QuantileTransformer\nfrom sklearn.preprocessing import FunctionTransformer\nfrom sklearn.preprocessing import PolynomialFeatures\nfrom sklearn.neighbors import KNeighborsClassifier\nfrom sklearn.preprocessing import KBinsDiscretizer\n# Import StandardScaler from scikit-learn\n\nfrom sklearn.experimental import enable_iterative_imputer\nfrom sklearn.impute import SimpleImputer\nfrom sklearn.impute import KNNImputer,IterativeImputer\nfrom sklearn.feature_extraction.text import CountVectorizer\nfrom sklearn.compose import make_column_transformer,ColumnTransformer\nfrom sklearn.pipeline import make_pipeline, Pipeline,FeatureUnion\nfrom sklearn.manifold import TSNE\n# Import train_test_split()\n# Metrics\nfrom sklearn.metrics import roc_auc_score, average_precision_score\nfrom sklearn.metrics import make_scorer,mean_absolute_error\nfrom sklearn.metrics import mean_squared_error\nfrom sklearn.metrics import roc_curve,confusion_matrix\nfrom datetime import datetime, date\nfrom sklearn.linear_model import ElasticNet, Lasso,  BayesianRidge, LassoLarsIC\nfrom sklearn.linear_model import LinearRegression, RidgeCV\nfrom sklearn.linear_model import LogisticRegression\n\n#import tensorflow as tf \n#from tensorflow.keras import layers\n#from tensorflow.keras.callbacks import EarlyStopping\n#from tensorflow.keras.callbacks import LearningRateScheduler\n#import smogn\nfrom sklearn.experimental import enable_hist_gradient_boosting\nfrom sklearn.base import BaseEstimator, TransformerMixin, RegressorMixin, clone\nfrom sklearn.kernel_ridge import KernelRidge\nfrom sklearn.ensemble import GradientBoostingRegressor,RandomForestRegressor\nfrom sklearn.ensemble import RandomForestClassifier\nfrom sklearn.ensemble import HistGradientBoostingClassifier\n# For training random forest model\nimport lightgbm as lgb\nfrom scipy import sparse\nfrom sklearn.neighbors import KNeighborsRegressor \nfrom sklearn.decomposition import PCA\nfrom sklearn.cluster import KMeans\nfrom yellowbrick.cluster import KElbowVisualizer\n# Model selection\nfrom sklearn.model_selection import StratifiedKFold\nfrom sklearn.feature_selection import SelectKBest\nfrom sklearn.feature_selection import f_regression,f_classif,chi2\nfrom sklearn.feature_selection import mutual_info_regression\nfrom sklearn.feature_selection import SelectPercentile\nfrom sklearn.feature_selection import mutual_info_classif,VarianceThreshold\n\nfrom sklearn.model_selection import train_test_split\nfrom sklearn.model_selection import KFold\nfrom sklearn.model_selection import GridSearchCV\nfrom sklearn.model_selection import cross_val_score\nfrom lightgbm import LGBMClassifier\nimport lightgbm as lgbm\n#from catboost import CatBoostRegressor, CatBoostClassifier\nfrom sklearn.naive_bayes import GaussianNB\nfrom sklearn import svm\nfrom xgboost import XGBClassifier,XGBRegressor\nfrom sklearn import set_config\nfrom itertools import combinations\n# Cluster :\nfrom sklearn.cluster import MiniBatchKMeans\n#from yellowbrick.cluster import KElbowVisualizer\n#import smong \nimport category_encoders as ce\nimport warnings\nimport optuna \nfrom joblib import Parallel, delayed\nimport joblib \nfrom sklearn import set_config\nfrom typing import List, Optional, Union\nset_config(display='diagram')\nwarnings.filterwarnings('ignore')","metadata":{"_cell_guid":"ddedf45c-cdd2-4013-973f-6ccf6c78347a","_uuid":"20c9b28e-4c93-447d-8210-cad89f404354","jupyter":{"outputs_hidden":false},"papermill":{"duration":2.476153,"end_time":"2021-12-05T19:44:31.236947","exception":false,"start_time":"2021-12-05T19:44:28.760794","status":"completed"},"tags":[],"collapsed":false,"execution":{"iopub.status.busy":"2021-12-24T21:50:07.315748Z","iopub.execute_input":"2021-12-24T21:50:07.316021Z","iopub.status.idle":"2021-12-24T21:50:10.651983Z","shell.execute_reply.started":"2021-12-24T21:50:07.315943Z","shell.execute_reply":"2021-12-24T21:50:10.651275Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"\n##  Load the data","metadata":{"_cell_guid":"38c6befb-892d-4ef3-9c63-13be5959b671","_uuid":"2953f9f3-02f8-4fa9-a7fc-cb93565c2183","papermill":{"duration":0.024781,"end_time":"2021-12-05T19:44:31.287383","exception":false,"start_time":"2021-12-05T19:44:31.262602","status":"completed"},"tags":[]}},{"cell_type":"code","source":"%%time \ntrain = pd.read_csv('../input/GiveMeSomeCredit/cs-training.csv')\ntest = pd.read_csv('../input/GiveMeSomeCredit/cs-test.csv')\ntrain.head(3)","metadata":{"_cell_guid":"98a5b4a6-90e9-449d-96cc-0d85c9ff1c77","_uuid":"e086592f-9f6a-4592-80b5-c1e7ad227e02","jupyter":{"outputs_hidden":false},"papermill":{"duration":14.803784,"end_time":"2021-12-05T19:44:46.11655","exception":false,"start_time":"2021-12-05T19:44:31.312766","status":"completed"},"tags":[],"collapsed":false,"execution":{"iopub.status.busy":"2021-12-24T21:50:10.65343Z","iopub.execute_input":"2021-12-24T21:50:10.653695Z","iopub.status.idle":"2021-12-24T21:50:11.192784Z","shell.execute_reply.started":"2021-12-24T21:50:10.653658Z","shell.execute_reply":"2021-12-24T21:50:11.192036Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"##  Convert Dtypes :","metadata":{"papermill":{"duration":0.025311,"end_time":"2021-12-05T19:44:46.2203","exception":false,"start_time":"2021-12-05T19:44:46.194989","status":"completed"},"tags":[]}},{"cell_type":"code","source":"# Convert Dtypes :\ntrain[train.select_dtypes(['int64','int16','float16','float32','float64','int8']).columns] = train[train.select_dtypes(['int64','int16','float16','float32','float64','int8']).columns].apply(pd.to_numeric)\ntrain[train.select_dtypes(['object','category']).columns] = train.select_dtypes(['object','category']).apply(lambda x: x.astype('category'))\n# Convert Dtypes :\ntest[test.select_dtypes(['int64','int16','float16','float32','float64','int8']).columns] = test[test.select_dtypes(['int64','int16','float16','float32','float64','int8']).columns].apply(pd.to_numeric)\ntest[test.select_dtypes(['object','category']).columns] = test.select_dtypes(['object','category']).apply(lambda x: x.astype('category'))","metadata":{"papermill":{"duration":42.444095,"end_time":"2021-12-05T19:45:28.690042","exception":false,"start_time":"2021-12-05T19:44:46.245947","status":"completed"},"tags":[],"execution":{"iopub.status.busy":"2021-12-24T21:50:11.193895Z","iopub.execute_input":"2021-12-24T21:50:11.194274Z","iopub.status.idle":"2021-12-24T21:50:11.284069Z","shell.execute_reply.started":"2021-12-24T21:50:11.194237Z","shell.execute_reply":"2021-12-24T21:50:11.283341Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"## Reduce memory","metadata":{}},{"cell_type":"code","source":"# Author : https://www.kaggle.com/gemartin/load-data-reduce-memory-usage\ndef reduce_mem_usage(df):\n    \"\"\" iterate through all the columns of a dataframe and modify the data type\n        to reduce memory usage.        \n    \"\"\"\n    start_mem = df.memory_usage().sum() / 1024**2\n    print('Memory usage of dataframe is {:.2f} MB'.format(start_mem))\n    \n    for col in df.columns:\n        col_type = df[col].dtype\n        name =df[col].dtype.name \n        \n        if col_type != object and col_type.name != 'category':\n        #if name != \"category\":    \n            c_min = df[col].min()\n            c_max = df[col].max()\n            if str(col_type)[:3] == 'int':\n                if c_min > np.iinfo(np.int8).min and c_max < np.iinfo(np.int8).max:\n                    df[col] = df[col].astype(np.int8)\n                elif c_min > np.iinfo(np.int16).min and c_max < np.iinfo(np.int16).max:\n                    df[col] = df[col].astype(np.int16)\n                elif c_min > np.iinfo(np.int32).min and c_max < np.iinfo(np.int32).max:\n                    df[col] = df[col].astype(np.int32)\n                elif c_min > np.iinfo(np.int64).min and c_max < np.iinfo(np.int64).max:\n                    df[col] = df[col].astype(np.int64)  \n            else:\n                if c_min > np.finfo(np.float16).min and c_max < np.finfo(np.float16).max:\n                    df[col] = df[col].astype(np.float16)\n                elif c_min > np.finfo(np.float32).min and c_max < np.finfo(np.float32).max:\n                    df[col] = df[col].astype(np.float32)\n                else:\n                    df[col] = df[col].astype(np.float64)\n        else:\n            df[col] = df[col].astype('category')\n\n    end_mem = df.memory_usage().sum() / 1024**2\n    print('Memory usage after optimization is: {:.2f} MB'.format(end_mem))\n    print('Decreased by {:.1f}%'.format(100 * (start_mem - end_mem) / start_mem))\n    \n    return df\n\ntrain= reduce_mem_usage(train)\ntest= reduce_mem_usage(test)","metadata":{"execution":{"iopub.status.busy":"2021-12-24T21:50:11.285869Z","iopub.execute_input":"2021-12-24T21:50:11.286103Z","iopub.status.idle":"2021-12-24T21:50:11.344975Z","shell.execute_reply.started":"2021-12-24T21:50:11.28607Z","shell.execute_reply":"2021-12-24T21:50:11.344208Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"# X and Y\n","metadata":{}},{"cell_type":"code","source":"# Cardinality : \n# - RevolvingUtilizationOfUnsecuredLines :125728, high Outlier\n# - DebtRatio :114194 , high Outlier \n# deal with outlier + bin \nPERCENTAGE = [\"RevolvingUtilizationOfUnsecuredLines\", \"DebtRatio\"]\n# MonthlyIncome:13594 , high outlier +bin \nREAL= [\"MonthlyIncome\"]\n# Can be considred as cat \nNUMERIC_DISCRET_low = [\"NumberOfDependents\",\n                       \"NumberOfTime60-89DaysPastDueNotWorse\",\n                       \"NumberRealEstateLoansOrLines\",\n                       \"NumberOfTimes90DaysLate\",\n                       \"NumberOfOpenCreditLinesAndLoans\",\n                       \"NumberOfTime30-59DaysPastDueNotWorse\",\n                       \"age\"]\nLate_Pay_Cols = ['NumberOfTime30-59DaysPastDueNotWorse',\n                 'NumberOfTimes90DaysLate',\n                 'NumberOfTime60-89DaysPastDueNotWorse']\nTARGET = [\"SeriousDlqin2yrs\"]\n\n#also change the type for TARGET to categorical\n#df[TARGET] = df[TARGET].astype('category')","metadata":{"execution":{"iopub.status.busy":"2021-12-24T21:50:11.346189Z","iopub.execute_input":"2021-12-24T21:50:11.346421Z","iopub.status.idle":"2021-12-24T21:50:11.352773Z","shell.execute_reply.started":"2021-12-24T21:50:11.346385Z","shell.execute_reply":"2021-12-24T21:50:11.351699Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"# Target","metadata":{}},{"cell_type":"code","source":"y = train['SeriousDlqin2yrs']","metadata":{"execution":{"iopub.status.busy":"2021-12-24T21:50:11.354168Z","iopub.execute_input":"2021-12-24T21:50:11.355111Z","iopub.status.idle":"2021-12-24T21:50:11.363754Z","shell.execute_reply.started":"2021-12-24T21:50:11.355072Z","shell.execute_reply":"2021-12-24T21:50:11.363053Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"# Impute NA","metadata":{}},{"cell_type":"code","source":"%%time \nparam =  {   \"verbosity\": 0,\n            #\"objective\": \"binary:logistic\",\n            #\"eval_metric\": \"auc\",\n            'random_state': 42,\n            # regression\n            'objective':'reg:squarederror', \n             'eval_metric': 'mae',\n            'early_stopping_rounds':100 ,\n            'gpu_id':0, \n            'predictor':\"gpu_predictor\",\n            # use exact for small dataset.\n            #\"tree_method\": \"exact\",\n            # big data :\n             'tree_method': 'gpu_hist',\n            # defines booster, gblinear for linear functions.\n             'booster': 'gbtree', \n            'lambda': 8.544792472633987e-07,\n            'alpha': 0.31141671752487043,\n            'subsample': 0.8779467596981366, \n            'colsample_bytree': 0.9759532762677546,\n            'learning_rate': 0.008686087328805853, \n            'n_estimators': 6988,\n            'max_depth': 9,\n            'min_child_weight': 2, \n            'eta': 3.7603213457541647e-06,\n            'gamma': 2.1478058456847449e-07,\n            'grow_policy': 'lossguide'}\n                \n\n#model_xgb = XGBRegressor(\n       #objective=\"mae\",\n #   **xgb_params2)\n\nnumeric_transformer1 = Pipeline(\n                            steps=[\n                            ('imputer', SimpleImputer(strategy='median'\n                                                      ,add_indicator=True)),\n                            ('scaler', PowerTransformer()),#(Numerical Input, Numerical Output)\n                            # Create an SelectKBest object to select features with two best ANOVA F-Values\n                            #The F-value scores examine if, when we group the numerical feature by the target vector, the means for each group are significantly different\n                           # ('reducedim',  SelectPercentile(f_classif,percentile=90))\n                            ]\n                            )\nnumeric_transformer2 = Pipeline(\n                            steps=[\n                            #('imputer', SimpleImputer(strategy='median'\n                             #                         ,add_indicator=True)),\n                            ('scaler', PowerTransformer()),#(Numerical Input, Numerical Output)\n                            # Create an SelectKBest object to select features with two best ANOVA F-Values\n                            #The F-value scores examine if, when we group the numerical feature by the target vector, the means for each group are significantly different\n                           # ('reducedim',  SelectPercentile(f_classif,percentile=90))\n                            ]\n                            )\n\npipe_xgbr1 = Pipeline(\n                    steps=[\n                        ('preprocessor', numeric_transformer1),\n                        ('classifier', XGBRegressor(\n                      #objective=\"mae\",\n                       **param))\n                    ]\n                )\npipe_xgbr2 = Pipeline(\n                    steps=[\n                        ('preprocessor', numeric_transformer2),\n                        ('classifier', XGBRegressor(\n                      #objective=\"mae\",\n                       **param))\n                    ]\n                )","metadata":{"execution":{"iopub.status.busy":"2021-12-24T21:58:41.82043Z","iopub.execute_input":"2021-12-24T21:58:41.820892Z","iopub.status.idle":"2021-12-24T21:58:41.832993Z","shell.execute_reply.started":"2021-12-24T21:58:41.820856Z","shell.execute_reply":"2021-12-24T21:58:41.832005Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"# XGBR regression imputer \n## Predict income","metadata":{}},{"cell_type":"code","source":"%%time \ntrain=train.drop(['Unnamed: 0','SeriousDlqin2yrs'], axis=1)\ntest=test.drop(['Unnamed: 0','SeriousDlqin2yrs'], axis=1)\ntrain_final= pd.concat( [train, test], axis=0) \n#testdf_income= train_final[train_final['MonthlyIncome'].isnull()==True]\ntraindf_income = train_final[train_final['MonthlyIncome'].isnull()==False]\ny_income = traindf_income['MonthlyIncome']\nX_income=traindf_income.drop([\"MonthlyIncome\"],axis=1)\npipe_xgbr1.fit(X_income, y_income)\ntrain_income_missing=train[train['MonthlyIncome'].isnull()==True].drop([\"MonthlyIncome\"],axis=1)\ntest_income_missing=test[test['MonthlyIncome'].isnull()==True].drop([\"MonthlyIncome\"],axis=1)\ntrain_predicted = pipe_xgbr1.predict(train_income_missing)\ntest_predicted = pipe_xgbr1.predict(test_income_missing)\ntrain.loc[(train.MonthlyIncome.isnull()), 'MonthlyIncome'] = train_predicted\ntest.loc[(test.MonthlyIncome.isnull()), 'MonthlyIncome'] = test_predicted","metadata":{"execution":{"iopub.status.busy":"2021-12-24T21:58:46.86649Z","iopub.execute_input":"2021-12-24T21:58:46.86706Z","iopub.status.idle":"2021-12-24T22:01:01.823447Z","shell.execute_reply.started":"2021-12-24T21:58:46.867025Z","shell.execute_reply":"2021-12-24T22:01:01.822684Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"train.info()","metadata":{"execution":{"iopub.status.busy":"2021-12-24T22:01:01.825151Z","iopub.execute_input":"2021-12-24T22:01:01.82559Z","iopub.status.idle":"2021-12-24T22:01:01.846989Z","shell.execute_reply.started":"2021-12-24T22:01:01.82555Z","shell.execute_reply":"2021-12-24T22:01:01.845573Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"test.info()","metadata":{"execution":{"iopub.status.busy":"2021-12-24T22:01:01.848736Z","iopub.execute_input":"2021-12-24T22:01:01.849389Z","iopub.status.idle":"2021-12-24T22:01:01.870477Z","shell.execute_reply.started":"2021-12-24T22:01:01.849156Z","shell.execute_reply":"2021-12-24T22:01:01.869789Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"## Predict number of dependents","metadata":{}},{"cell_type":"code","source":"%%time \ntraindf_NumberOfDependents = train_final[train_final['NumberOfDependents'].isnull()==False]\ny_NumberOfDependents = traindf_NumberOfDependents['NumberOfDependents']\nX_NumberOfDependents=traindf_NumberOfDependents.drop([\"NumberOfDependents\"],axis=1)\npipe_xgbr2.fit(X_NumberOfDependents, y_NumberOfDependents)\ntrain_NumberOfDependents_missing=train[train['NumberOfDependents'].isnull()==True].drop([\"NumberOfDependents\"],axis=1)\ntest_NumberOfDependents_missing=test[test['NumberOfDependents'].isnull()==True].drop([\"NumberOfDependents\"],axis=1)\ntrain_predicted = pipe_xgbr2.predict(train_NumberOfDependents_missing)\ntest_predicted = pipe_xgbr2.predict(test_NumberOfDependents_missing)\ntrain.loc[(train.NumberOfDependents.isnull()), 'NumberOfDependents'] = train_predicted\ntest.loc[(test.NumberOfDependents.isnull()), 'NumberOfDependents'] = test_predicted","metadata":{"execution":{"iopub.status.busy":"2021-12-24T22:01:01.872538Z","iopub.execute_input":"2021-12-24T22:01:01.872951Z","iopub.status.idle":"2021-12-24T22:03:42.119075Z","shell.execute_reply.started":"2021-12-24T22:01:01.872915Z","shell.execute_reply":"2021-12-24T22:03:42.118353Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"train.info()","metadata":{"execution":{"iopub.status.busy":"2021-12-24T22:03:42.120474Z","iopub.execute_input":"2021-12-24T22:03:42.120876Z","iopub.status.idle":"2021-12-24T22:03:42.136901Z","shell.execute_reply.started":"2021-12-24T22:03:42.120836Z","shell.execute_reply":"2021-12-24T22:03:42.136184Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"test.info()","metadata":{"execution":{"iopub.status.busy":"2021-12-24T22:03:42.138236Z","iopub.execute_input":"2021-12-24T22:03:42.138519Z","iopub.status.idle":"2021-12-24T22:03:42.152894Z","shell.execute_reply.started":"2021-12-24T22:03:42.138472Z","shell.execute_reply":"2021-12-24T22:03:42.152174Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"## Add bin","metadata":{}},{"cell_type":"code","source":"# Add bin data \n# initializing append_str\nappend_str = 'cat_'\n# Append suffix / prefix to strings in list\nnum_features1=[\"RevolvingUtilizationOfUnsecuredLines\", \"DebtRatio\",\"MonthlyIncome\"]\nnum_features2=[\"NumberOfDependents\",\n                       \"NumberOfTime60-89DaysPastDueNotWorse\",\n                       \"NumberRealEstateLoansOrLines\",\n                       \"NumberOfTimes90DaysLate\",\n                       \"NumberOfOpenCreditLinesAndLoans\",\n                       \"NumberOfTime30-59DaysPastDueNotWorse\",\n                       \"age\"]\ncat_features1 = [append_str + sub for sub in num_features1]\ncat_features2 = [append_str + sub for sub in num_features2]\n\n# create the discretizer object with strategy quantile and 1000 bins\ndiscretizer1 = KBinsDiscretizer(n_bins=40, encode='ordinal',strategy='quantile')\ndiscretizer2 = KBinsDiscretizer(n_bins=4, encode='ordinal',strategy='quantile')\n\npipeline1 = Pipeline([\n        ('imputer', SimpleImputer( strategy='median')),\n        ('bin', discretizer1)\n    ])\n# fit the discretizer to the train set\npipeline1.fit(train.loc[:,num_features1])\n# apply the discretisation\ntrain_cat1 = pipeline1.transform(train.loc[:,num_features1])\ntest_cat1 = pipeline1.transform(test.loc[:,num_features1])\ntrain_df1=pd.DataFrame(train_cat1,columns=cat_features1).astype('category')\ntest_df1=pd.DataFrame(test_cat1,columns=cat_features1).astype('category')\ntrain_final1= pd.concat( [train.loc[:,num_features1], train_df1], axis=1) \ntest_final1= pd.concat( [test.loc[:,num_features1], test_df1], axis=1) \n\npipeline2 = Pipeline([\n        ('imputer', SimpleImputer( strategy='median')),\n        ('bin', discretizer2)\n    ])\n# fit the discretizer to the train set\npipeline2.fit(train.loc[:,num_features2])\n# apply the discretisation\ntrain_cat2 = pipeline2.transform(train.loc[:,num_features2])\ntest_cat2 = pipeline2.transform(test.loc[:,num_features2])\ntrain_df2=pd.DataFrame(train_cat2,columns=cat_features2).astype('category')\ntest_df2=pd.DataFrame(test_cat2,columns=cat_features2).astype('category')\ntrain_final2= pd.concat( [train.loc[:,num_features2], train_df2], axis=1) \ntest_final2= pd.concat( [test.loc[:,num_features2], test_df2], axis=1) \ntrain_final= pd.concat( [train_final1, train_final2], axis=1) \ntest_final= pd.concat( [test_final1, test_final2], axis=1) ","metadata":{"execution":{"iopub.status.busy":"2021-12-24T22:03:42.154209Z","iopub.execute_input":"2021-12-24T22:03:42.154477Z","iopub.status.idle":"2021-12-24T22:03:42.723439Z","shell.execute_reply.started":"2021-12-24T22:03:42.15444Z","shell.execute_reply":"2021-12-24T22:03:42.722731Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"# Final X and y","metadata":{}},{"cell_type":"code","source":"# Pour le train test\ntarget= \"SeriousDlqin2yrs\"\nX = train_final# axis=1\nX_test_final =test_final# axis=1","metadata":{"execution":{"iopub.status.busy":"2021-12-24T22:03:42.72475Z","iopub.execute_input":"2021-12-24T22:03:42.726664Z","iopub.status.idle":"2021-12-24T22:03:42.731066Z","shell.execute_reply.started":"2021-12-24T22:03:42.726634Z","shell.execute_reply":"2021-12-24T22:03:42.730384Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"X_test_final.info()","metadata":{"execution":{"iopub.status.busy":"2021-12-24T22:03:42.732379Z","iopub.execute_input":"2021-12-24T22:03:42.732658Z","iopub.status.idle":"2021-12-24T22:03:42.758081Z","shell.execute_reply.started":"2021-12-24T22:03:42.732624Z","shell.execute_reply":"2021-12-24T22:03:42.757441Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"X.info()","metadata":{"execution":{"iopub.status.busy":"2021-12-24T22:03:42.761698Z","iopub.execute_input":"2021-12-24T22:03:42.762313Z","iopub.status.idle":"2021-12-24T22:03:42.782299Z","shell.execute_reply.started":"2021-12-24T22:03:42.762276Z","shell.execute_reply":"2021-12-24T22:03:42.781642Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"del train\ndel test \ndel train_final\ndel test_final","metadata":{"execution":{"iopub.status.busy":"2021-12-24T22:03:42.78364Z","iopub.execute_input":"2021-12-24T22:03:42.783884Z","iopub.status.idle":"2021-12-24T22:03:42.787797Z","shell.execute_reply.started":"2021-12-24T22:03:42.783851Z","shell.execute_reply":"2021-12-24T22:03:42.787025Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"# Extract final cat  and num Features \n## Cat Features ","metadata":{}},{"cell_type":"code","source":"# select non-numeric columns\ncat_columns = X.select_dtypes(exclude=['int64','int16','float16','float32','float64','int8']).columns\ncat_columns","metadata":{"execution":{"iopub.status.busy":"2021-12-24T22:03:42.789207Z","iopub.execute_input":"2021-12-24T22:03:42.789877Z","iopub.status.idle":"2021-12-24T22:03:42.803179Z","shell.execute_reply.started":"2021-12-24T22:03:42.789841Z","shell.execute_reply":"2021-12-24T22:03:42.802436Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"**Num Features**\n\n","metadata":{"papermill":{"duration":0.027382,"end_time":"2021-12-05T19:45:39.124","exception":false,"start_time":"2021-12-05T19:45:39.096618","status":"completed"},"tags":[]}},{"cell_type":"code","source":"# select the float columns\nnum_columns = X.select_dtypes(include=['int64','int16','float16','float32','float64','int8']).columns\nnum_columns","metadata":{"papermill":{"duration":0.148909,"end_time":"2021-12-05T19:45:39.300094","exception":false,"start_time":"2021-12-05T19:45:39.151185","status":"completed"},"tags":[],"execution":{"iopub.status.busy":"2021-12-24T22:03:42.804621Z","iopub.execute_input":"2021-12-24T22:03:42.805065Z","iopub.status.idle":"2021-12-24T22:03:42.817841Z","shell.execute_reply.started":"2021-12-24T22:03:42.805028Z","shell.execute_reply":"2021-12-24T22:03:42.816824Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"##  Define preprocess Pipe \n\n1. Features Engineer\n\n1. Kmeans\n\n1. Sparse\n\n1. Poly\n\n1. Scaler/Transformer\n\n1. imput","metadata":{}},{"cell_type":"code","source":"class FeaturesEngineer(BaseEstimator, TransformerMixin):\n    def fit(self, X, y=None):\n        return self\n    def transform(self, X, y=None):\n        X=X.copy()\n        # Calculate some metrics across rows\n        X[\"num_missing\"]  = X.isnull().sum(axis=1)\n        X[\"std_row\"] = X.std(axis=1)\n        X[\"sem_row\"] = X.sem(axis=1)\n        X[\"abs_sum_row\"] = X.abs().sum(axis=1)\n        X[\"mean_row\"] = X.mean(axis=1)\n        X[\"max_row\"]= X.max(axis=1)\n        X[\"min_row\"]= X.min(axis=1)\n        X['Weighted_Sum_PastDue'] = 2 * X['NumberOfTime30-59DaysPastDueNotWorse'] + 3 * X['NumberOfTime60-89DaysPastDueNotWorse'] + 6 * X['NumberOfTimes90DaysLate']\n        X['90days_out_of_TotalPastDue'] = X['NumberOfTimes90DaysLate'] / (X['Weighted_Sum_PastDue'])\n        X.loc[X['Weighted_Sum_PastDue']==0, '90days_out_of_TotalPastDue'] = 0\n        X['RemainingLines'] = X['NumberOfOpenCreditLinesAndLoans'] - X['NumberRealEstateLoansOrLines']\n        X['Loans_vs_Other_Lines'] = X['RemainingLines'] / (1 + X['NumberRealEstateLoansOrLines'])\n        X['Debt_per_Real_Estate_Loan'] = X['DebtRatio'] / X['NumberRealEstateLoansOrLines']\n        X.loc[X['NumberRealEstateLoansOrLines']==0, 'Debt_per_Real_Estate_Loan'] = 0\n        X['Disposable_Income_per_person'] = (X['MonthlyIncome'] - X['DebtRatio']) / (X['NumberOfDependents'] + 1)\n        X.loc[X['NumberOfDependents']==0, 'Disposable_Income_per_person'] = 0\n        X['RemainingLines_per_person'] = X['RemainingLines'] / (X['NumberOfDependents'] + 1)\n        X['NumberRE_X_DebtRatio_X_age'] = X['NumberRealEstateLoansOrLines'] * X['DebtRatio'] / X['age']\n        X['RevolvingUtilization_per_age'] = X['RevolvingUtilizationOfUnsecuredLines'] / X['age']\n        X[X==np.inf]=np.nan\n        X=reduce_mem_usage(X)\n        return X  ","metadata":{"execution":{"iopub.status.busy":"2021-12-24T22:03:42.819298Z","iopub.execute_input":"2021-12-24T22:03:42.819618Z","iopub.status.idle":"2021-12-24T22:03:42.831561Z","shell.execute_reply.started":"2021-12-24T22:03:42.819565Z","shell.execute_reply":"2021-12-24T22:03:42.830742Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"class MiniKmeansTransformerEncoder(BaseEstimator, TransformerMixin):\n    def __init__(self, num_clusters = 11, encoder=ce.woe.WOEEncoder()):\n        self.num_clusters = num_clusters\n        self.encoder= encoder\n        if self.num_clusters > 0:\n            self.kmeans = MiniBatchKMeans(n_clusters=self.num_clusters, random_state=0)\n    \n    def fit(self, X, y=None):\n        if self.num_clusters > 0:\n            self.kmeans.fit(X)\n            preds=self.kmeans.predict(X)\n            preds=pd.DataFrame(preds, columns=['kmeans']).astype('category')\n            self.encoder.fit(preds,y)\n        return self\n    \n    def transform(self, X, y=None):\n        pred_classes = self.kmeans.predict(X)\n        pred_classes=pd.DataFrame(pred_classes, columns=['kmeans']).astype('category')\n        pred_encoded = self.encoder.transform(pred_classes)\n        return np.hstack((X, pred_encoded))\n        #return pred_encoded","metadata":{"execution":{"iopub.status.busy":"2021-12-24T22:03:42.833201Z","iopub.execute_input":"2021-12-24T22:03:42.833842Z","iopub.status.idle":"2021-12-24T22:03:42.84365Z","shell.execute_reply.started":"2021-12-24T22:03:42.833806Z","shell.execute_reply":"2021-12-24T22:03:42.842896Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# Cat pipeline\ncategorical_transformer = Pipeline(\n                    steps=[\n                        ('imputer', SimpleImputer(strategy='most_frequent',\n                                                  fill_value='missing',\n                                                  add_indicator=True)),\n                        ('encoder',  ce.woe.WOEEncoder()),#(Numerical Input, Categorical Output)\n\n                    ]\n                    ) \n#Define vnum pipeline\nnumeric_transformer = Pipeline(\n                            steps=[\n                            ('imputer', SimpleImputer(strategy='median'\n                                                      ,add_indicator=True)),\n                            ('scaler', PowerTransformer()),#(Numerical Input, Numerical Output)\n                           ('kmeans',MiniKmeansTransformerEncoder()),\n                            ('polynominal_features', PolynomialFeatures(degree=2)),\n                            ]\n                            )\n# Features union cat + num \n# WOE+PowerTransformer\npreprocessor_woe_powertransformer = ColumnTransformer(\n            transformers=[\n                ('numerical', numeric_transformer, num_columns),\n               # ('categorical', categorical_transformer, cat_columns)\n            ])","metadata":{"execution":{"iopub.status.busy":"2021-12-24T22:03:42.845154Z","iopub.execute_input":"2021-12-24T22:03:42.845432Z","iopub.status.idle":"2021-12-24T22:03:42.855528Z","shell.execute_reply.started":"2021-12-24T22:03:42.845397Z","shell.execute_reply":"2021-12-24T22:03:42.854806Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"# First pipe to tune : \nimputer + transformer + kmeans fe+ploy fe ","metadata":{}},{"cell_type":"code","source":"preprocessor_woe_powertransformer","metadata":{"execution":{"iopub.status.busy":"2021-12-24T22:03:42.856956Z","iopub.execute_input":"2021-12-24T22:03:42.857474Z","iopub.status.idle":"2021-12-24T22:03:42.929832Z","shell.execute_reply.started":"2021-12-24T22:03:42.857437Z","shell.execute_reply":"2021-12-24T22:03:42.929145Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"## CV Design","metadata":{}},{"cell_type":"code","source":"N_FOLD = 5\ncross_validation_design = StratifiedKFold( n_splits=N_FOLD,\n                                           shuffle=True\n                                        ,random_state=1)\ncross_validation_design","metadata":{"execution":{"iopub.status.busy":"2021-12-24T22:03:42.930938Z","iopub.execute_input":"2021-12-24T22:03:42.931362Z","iopub.status.idle":"2021-12-24T22:03:42.937196Z","shell.execute_reply.started":"2021-12-24T22:03:42.931325Z","shell.execute_reply":"2021-12-24T22:03:42.936428Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"# Optuna","metadata":{}},{"cell_type":"code","source":" def objective_lgbm_pipe1(trial,X=X,y=y):\n    param = {\n        \"objective\": \"binary\",\n        'random_state': 42,\n         'metric': 'auc',\n        \"verbosity\": -1,\n        \"boosting_type\": \"gbdt\",\n        \"device\": \"gpu\",\n        #\"early_stopping_rounds\":100,\n        \"learning_rate\": trial.suggest_float(\"learning_rate\",0.005 ,0.2),\n        \"n_estimators\" : trial.suggest_int(\"n_estimators\" , 1000 , 10000),\n        \"lambda_l1\": trial.suggest_float(\"lambda_l1\", 1e-8, 10.0, log=True),\n        \"lambda_l2\": trial.suggest_float(\"lambda_l2\", 1e-8, 10.0, log=True),\n        \"num_leaves\": trial.suggest_int(\"num_leaves\", 2, 256),\n        \"feature_fraction\": trial.suggest_float(\"feature_fraction\", 0.4, 1.0),\n        \"bagging_fraction\": trial.suggest_float(\"bagging_fraction\", 0.4, 1.0),\n        \"bagging_freq\": trial.suggest_int(\"bagging_freq\", 1, 7),\n        \"min_child_samples\": trial.suggest_int(\"min_child_samples\", 5, 100),\n    }\n    pipe_lgbm_pipe1 = Pipeline(\n                    steps=[\n                        ('preprocessor', preprocessor_woe_powertransformer),\n                        ('classifier',lgbm.LGBMClassifier(\n                       **param))\n                    ]\n                )\n    roc_auc = list()\n    oof = np.empty((X.shape[0],))\n    predictions=[]\n    mean_auc = 0\n    for fold, (train_idx, test_idx) in enumerate(cross_validation_design.split(X, y)):    \n        X_train, y_train = X.iloc[list(train_idx), :], y.iloc[list(train_idx)]\n        X_test, y_test = X.iloc[list(test_idx), :],y.iloc[list(test_idx)]\n        pipe_lgbm_pipe1.fit(X_train,y_train)\n        preds = pipe_lgbm_pipe1.predict_proba(X_test)[:,1]\n        oof[test_idx] = preds\n        auc_score= roc_auc_score(y_true=y_test, y_score=preds)\n        roc_auc.append(auc_score)\n        print(f\"Fold {fold} | AUC: {auc_score}\")\n        mean_auc += auc_score / N_FOLD\n    final_auc = mean_auc   \n    return final_auc              ","metadata":{"execution":{"iopub.status.busy":"2021-12-24T22:05:43.090963Z","iopub.execute_input":"2021-12-24T22:05:43.091235Z","iopub.status.idle":"2021-12-24T22:05:43.104208Z","shell.execute_reply.started":"2021-12-24T22:05:43.091201Z","shell.execute_reply":"2021-12-24T22:05:43.102579Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"%%time \nstudy_lgbm_pipe1 = optuna.create_study(direction=\"maximize\")\nstudy_lgbm_pipe1.optimize(objective_lgbm_pipe1 ,n_trials=1)","metadata":{"execution":{"iopub.status.busy":"2021-12-24T22:05:45.905284Z","iopub.execute_input":"2021-12-24T22:05:45.905704Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"print(\"Numbers of finished trials : \" , len(study_lgbm_pipe2.trials))\nprint(\"Best Trials : \", study_lgbm_pipe2.best_trial.params)\nprint(\"Best Values : \" , study_lgbm_pipe2.best_value)","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"    {'learning_rate': 0.06012860685290609, 'n_estimators': 7071, 'lambda_l1': 0.2888413842261667, 'lambda_l2': 0.0002307374280498992, 'num_leaves': 2, 'feature_fraction': 0.5682502860868459, 'bagging_fraction': 0.6183283251138053, 'bagging_freq': 3, 'min_child_samples': 60}. Best is trial 22 with value: 0.8642312087296007\n    \n    -------------------------------------------------------------------------\n    \n        Best one : \n\n     Trial 14 finished with value: 0.8643424882665558 and parameters: {'learning_rate': 0.005282912028625591, 'n_estimators': 1491, 'lambda_l1': 2.5825901359648176e-05, 'lambda_l2': 4.490094872871969, 'num_leaves': 76, 'feature_fraction': 0.7099515479738928, 'bagging_fraction': 0.8225459856082522, 'bagging_freq': 3, 'min_child_samples': 35}. Best is trial 14 with value: 0.8643424882665558","metadata":{}}]}